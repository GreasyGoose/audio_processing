{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "asr_lab_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RcyxmRJGqlY"
      },
      "source": [
        "# Практика №4\n",
        "\n",
        "Теперь мы построим и обучим простую end-to-end модель. Будем работать с пропатченной версией уже готового [пайплайна](https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch). Также нам пригодится [ESPnet](https://github.com/espnet/espnet) для использования модели [Transformer](http://jalammar.github.io/illustrated-transformer/) в качестве энкодера."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDbO_rrWGq7j"
      },
      "source": [
        "### Bootstrap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyS3YnuirGak",
        "outputId": "179e9a75-2be8-4e6c-f479-67f28a95a461"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May  7 23:31:08 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzJyomV1JaLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e2a45e-4a86-4a32-d02e-ccd62594571d"
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 15.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TROAsHTXHWik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc0c801-317c-4545-e4b5-20a2ecb01da3"
      },
      "source": [
        "!gdown --id '1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6'\n",
        "\n",
        "!unzip -q lab4.zip\n",
        "!rm -rf lab4.zip sample_data\n",
        "%cd lab4"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6\n",
            "To: /content/lab4.zip\n",
            "\r0.00B [00:00, ?B/s]\r2.77MB [00:00, 86.6MB/s]\n",
            "/content/lab4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4wcCtkIH2dn"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from utils import TextTransform\n",
        "from utils import cer\n",
        "from utils import wer\n",
        "\n",
        "from espnet.nets.pytorch_backend.transformer.embedding import PositionalEncoding\n",
        "# from espnet.nets.pytorch_backend.transformer.encoder_layer import EncoderLayer #For initial model\n",
        "from espnet.nets.pytorch_backend.transformer.repeat import repeat\n",
        "from espnet.nets.pytorch_backend.transformer.attention import MultiHeadedAttention\n",
        "from espnet.nets.pytorch_backend.transformer.positionwise_feed_forward import PositionwiseFeedForward\n",
        "from espnet.nets.pytorch_backend.transformer.layer_norm import LayerNorm\n",
        "from espnet.nets.pytorch_backend.nets_utils import make_pad_mask"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAc35wiMu8Ds"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaESUZiHJgfN"
      },
      "source": [
        "train_audio_transforms = torch.nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=400, hop_length=160, n_mels=80),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
        "                                                              n_fft=400,\n",
        "                                                              hop_length=160,\n",
        "                                                              n_mels=80)\n",
        "\n",
        "# text_transform = TextTransform() #for baseline Transformer model\n",
        "\n",
        "#-----------------------------TODO №2-----------------------------------\n",
        "# Заменить графемный токенайзер на сабвордовый TextTransformBPE\n",
        "text_transform = TextTransformBPE('/content/lab4/train_clean_100_text_clean.txt')\n",
        "#-----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0])\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = torch.nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=4000, collapse_repeated=True): #blank_label=28 for baseline Transformer model with TextTransform()\n",
        "    arg_maxes = torch.argmax(output, dim=2)\n",
        "    decodes = []\n",
        "    targets = []\n",
        "    for i, args in enumerate(arg_maxes):\n",
        "        decode = []\n",
        "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "        for j, index in enumerate(args):\n",
        "            if index != blank_label:\n",
        "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
        "                    continue\n",
        "                decode.append(index.item())\n",
        "        decodes.append(text_transform.int_to_text(decode))\n",
        "    return decodes, targets"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OqoVLnrJsCV"
      },
      "source": [
        "class TransformerModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size=80,\n",
        "        output_size=29,\n",
        "        conv2d_filters=32,\n",
        "        attention_dim=360,\n",
        "        attention_heads=8,\n",
        "        feedforward_dim=1024,\n",
        "        num_layers=10,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        \n",
        "        self.conv_in = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(conv2d_filters, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "        self.conv_out = torch.nn.Sequential(\n",
        "            torch.nn.Linear(conv2d_filters * ((input_size // 2) // 2), attention_dim),\n",
        "            PositionalEncoding(attention_dim, 0.1),\n",
        "        )\n",
        "        positionwise_layer = PositionwiseFeedForward\n",
        "        positionwise_layer_args = (attention_dim, feedforward_dim, dropout)\n",
        "        self.encoder_layer = repeat(\n",
        "            num_layers,\n",
        "            lambda lnum: EncoderLayer(\n",
        "                attention_dim,\n",
        "                MultiHeadedAttention(\n",
        "                    attention_heads, attention_dim, dropout\n",
        "                ),\n",
        "                positionwise_layer(*positionwise_layer_args),\n",
        "                dropout,\n",
        "                normalize_before=True,\n",
        "                concat_after=False,\n",
        "            ),\n",
        "        )\n",
        "        self.after_norm = LayerNorm(attention_dim)\n",
        "        self.final_layer = torch.nn.Linear(attention_dim, output_size)\n",
        "\n",
        "    def forward(self, x, ilens):\n",
        "        x = x.unsqueeze(1)  # (b, c, t, f)\n",
        "        x = self.conv_in(x)\n",
        "        b, c, t, f = x.size()\n",
        "        x = self.conv_out(x.transpose(1, 2).contiguous().view(b, t, c * f))\n",
        "        masks = (~make_pad_mask(ilens)[:, None, :])[:, :, ::4].to(x.device)\n",
        "        x, _ = self.encoder_layer(x, masks)\n",
        "        x = self.after_norm(x)\n",
        "        x = self.final_layer(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2p_8IjeKkqq"
      },
      "source": [
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "\n",
        "    train_loss = []\n",
        "\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data \n",
        "        spectrograms, labels = spectrograms[:, :, :,:max(input_lengths)].to(device), labels.to(device) #(batch, 1, feat_dim, time)\n",
        "        spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch, time, feat_dim,)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(spectrograms, input_lengths)  # (batch, time, n_classes)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "        input_lengths = [x // 4 for x in input_lengths]\n",
        "\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        loss.backward()\n",
        "        \n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLR: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(spectrograms), data_len,\n",
        "                100. * batch_idx / len(train_loader), loss.item(), scheduler.get_last_lr()[0]))\n",
        "            \n",
        "    return np.mean(train_loss)\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "            spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch time, feat_dim,)\n",
        "            \n",
        "            output = model(spectrograms, input_lengths)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "            input_lengths = [x // 4 for x in input_lengths]\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "            for j in range(len(decoded_preds)):\n",
        "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
        "    return test_loss"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzEbtsB1LKsh"
      },
      "source": [
        "def main(learning_rate=1e-5, batch_size=20, test_batch_size=7, epochs=10,\n",
        "        train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
        "    \n",
        "    hparams = {\n",
        "        \"input_size\": 80,\n",
        "        \"output_size\": 4001, #\"output_size\": 29 for baseline Transformer model with TextTransform() \n",
        "        \"conv2d_filters\": 32,\n",
        "        \"attention_dim\": 360,\n",
        "        \"attention_heads\": 8,\n",
        "        \"feedforward_dim\": 1024,\n",
        "        \"num_blocks\":10,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=test_batch_size,\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "    \n",
        "\n",
        "# # -----BASELINE MODEL--------------------\n",
        "#     model = TransformerModel(\n",
        "#         hparams['input_size'],\n",
        "#         hparams['output_size'],\n",
        "#         hparams['conv2d_filters'],\n",
        "#         hparams['attention_dim'],\n",
        "#         hparams['attention_heads'],\n",
        "#         hparams['feedforward_dim'],\n",
        "#         hparams['num_layers'],\n",
        "#         hparams['dropout']).to(device)\n",
        "# # -----------------------------------------\n",
        "\n",
        "    \n",
        "    model = ConformerModel(\n",
        "        hparams['input_size'],\n",
        "        hparams['output_size'],\n",
        "        hparams['conv2d_filters'],\n",
        "        hparams['attention_dim'],\n",
        "        hparams['attention_heads'],\n",
        "        hparams['feedforward_dim'],\n",
        "        hparams['num_blocks'],\n",
        "        hparams['dropout']).to(device)   \n",
        "\n",
        "    print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = torch.nn.CTCLoss(blank=4000, zero_infinity=False).to(device) # blank=28 for init model with TextTransform()\n",
        "\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "    \n",
        "    train_history = []\n",
        "    val_history = []\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        !date\n",
        "        train_loss = train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
        "        val_loss = test(model, device, test_loader, criterion, epoch)\n",
        "\n",
        "        train_history.append(train_loss)\n",
        "        val_history.append(val_loss)\n",
        "\n",
        "        with open(os.path.join(\"runs\", \"ep{}_checkpoint.pth\".format(epoch)), \"wb\") as fp:\n",
        "          torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': val_loss,\n",
        "            'train_history': train_history,\n",
        "            'valid_history': val_history,   \n",
        "            }, fp)\n",
        "    return train_history, val_history"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eExZLsUiLeXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a2b683-254f-49f5-e9fc-766d1e9815ed"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 10\n",
        "test_batch_size = 7\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "os.makedirs(\"runs\", exist_ok=True)\n",
        "\n",
        "train_history, val_history = main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConformerModel(\n",
            "  (conv_in): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): Linear(in_features=640, out_features=360, bias=True)\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (encoder_layer): MultiSequential(\n",
            "    (0): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm_ff): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm_mha): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (1): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm_ff): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm_mha): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (2): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm_ff): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm_mha): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (3): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm_ff): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm_mha): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (4): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm_ff): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm_mha): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (5): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm_ff): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm_mha): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (6): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm_ff): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm_mha): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (7): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm_ff): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm_mha): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (8): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm_ff): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm_mha): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (9): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm_ff): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm_mha): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (after_norm): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "  (final_layer): Linear(in_features=360, out_features=4001, bias=True)\n",
            ")\n",
            "Num Model Parameters 14284849\n",
            "Fri May  7 23:46:50 UTC 2021\n",
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 52.876720\tLR: 0.000040\n",
            "Train Epoch: 1 [1000/28539 (4%)]\tLoss: 7.228498\tLR: 0.000051\n",
            "Train Epoch: 1 [2000/28539 (7%)]\tLoss: 6.891717\tLR: 0.000063\n",
            "Train Epoch: 1 [3000/28539 (11%)]\tLoss: 6.857337\tLR: 0.000074\n",
            "Train Epoch: 1 [4000/28539 (14%)]\tLoss: 6.955213\tLR: 0.000085\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 6.868241\tLR: 0.000096\n",
            "Train Epoch: 1 [6000/28539 (21%)]\tLoss: 6.866759\tLR: 0.000107\n",
            "Train Epoch: 1 [7000/28539 (25%)]\tLoss: 6.974304\tLR: 0.000119\n",
            "Train Epoch: 1 [8000/28539 (28%)]\tLoss: 7.071786\tLR: 0.000130\n",
            "Train Epoch: 1 [9000/28539 (32%)]\tLoss: 6.852877\tLR: 0.000141\n",
            "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 6.928719\tLR: 0.000152\n",
            "Train Epoch: 1 [11000/28539 (39%)]\tLoss: 6.933452\tLR: 0.000163\n",
            "Train Epoch: 1 [12000/28539 (42%)]\tLoss: 6.890958\tLR: 0.000175\n",
            "Train Epoch: 1 [13000/28539 (46%)]\tLoss: 6.846207\tLR: 0.000186\n",
            "Train Epoch: 1 [14000/28539 (49%)]\tLoss: 6.940254\tLR: 0.000197\n",
            "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 6.767045\tLR: 0.000208\n",
            "Train Epoch: 1 [16000/28539 (56%)]\tLoss: 6.868340\tLR: 0.000220\n",
            "Train Epoch: 1 [17000/28539 (60%)]\tLoss: 6.842098\tLR: 0.000231\n",
            "Train Epoch: 1 [18000/28539 (63%)]\tLoss: 6.980134\tLR: 0.000242\n",
            "Train Epoch: 1 [19000/28539 (67%)]\tLoss: 7.039634\tLR: 0.000253\n",
            "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 6.752397\tLR: 0.000264\n",
            "Train Epoch: 1 [21000/28539 (74%)]\tLoss: 6.779884\tLR: 0.000276\n",
            "Train Epoch: 1 [22000/28539 (77%)]\tLoss: 6.936831\tLR: 0.000287\n",
            "Train Epoch: 1 [23000/28539 (81%)]\tLoss: 6.598039\tLR: 0.000298\n",
            "Train Epoch: 1 [24000/28539 (84%)]\tLoss: 6.633672\tLR: 0.000309\n",
            "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 6.641898\tLR: 0.000320\n",
            "Train Epoch: 1 [26000/28539 (91%)]\tLoss: 6.752507\tLR: 0.000332\n",
            "Train Epoch: 1 [27000/28539 (95%)]\tLoss: 6.713057\tLR: 0.000343\n",
            "Train Epoch: 1 [28000/28539 (98%)]\tLoss: 6.662388\tLR: 0.000354\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 6.6328, Average CER: 0.997076 Average WER: 0.9979\n",
            "\n",
            "Fri May  7 23:54:15 UTC 2021\n",
            "Train Epoch: 2 [0/28539 (0%)]\tLoss: 6.580247\tLR: 0.000360\n",
            "Train Epoch: 2 [1000/28539 (4%)]\tLoss: 6.640965\tLR: 0.000371\n",
            "Train Epoch: 2 [2000/28539 (7%)]\tLoss: 6.600604\tLR: 0.000383\n",
            "Train Epoch: 2 [3000/28539 (11%)]\tLoss: 6.321660\tLR: 0.000394\n",
            "Train Epoch: 2 [4000/28539 (14%)]\tLoss: 6.242759\tLR: 0.000405\n",
            "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 6.291473\tLR: 0.000416\n",
            "Train Epoch: 2 [6000/28539 (21%)]\tLoss: 6.413478\tLR: 0.000427\n",
            "Train Epoch: 2 [7000/28539 (25%)]\tLoss: 6.358007\tLR: 0.000439\n",
            "Train Epoch: 2 [8000/28539 (28%)]\tLoss: 6.473280\tLR: 0.000450\n",
            "Train Epoch: 2 [9000/28539 (32%)]\tLoss: 5.674850\tLR: 0.000461\n",
            "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 6.263775\tLR: 0.000472\n",
            "Train Epoch: 2 [11000/28539 (39%)]\tLoss: 6.061572\tLR: 0.000483\n",
            "Train Epoch: 2 [12000/28539 (42%)]\tLoss: 6.069897\tLR: 0.000495\n",
            "Train Epoch: 2 [13000/28539 (46%)]\tLoss: 6.036027\tLR: 0.000506\n",
            "Train Epoch: 2 [14000/28539 (49%)]\tLoss: 5.744599\tLR: 0.000517\n",
            "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 5.878890\tLR: 0.000528\n",
            "Train Epoch: 2 [16000/28539 (56%)]\tLoss: 5.574967\tLR: 0.000540\n",
            "Train Epoch: 2 [17000/28539 (60%)]\tLoss: 5.533855\tLR: 0.000551\n",
            "Train Epoch: 2 [18000/28539 (63%)]\tLoss: 5.773177\tLR: 0.000562\n",
            "Train Epoch: 2 [19000/28539 (67%)]\tLoss: 5.491566\tLR: 0.000573\n",
            "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 5.636652\tLR: 0.000584\n",
            "Train Epoch: 2 [21000/28539 (74%)]\tLoss: 5.562602\tLR: 0.000596\n",
            "Train Epoch: 2 [22000/28539 (77%)]\tLoss: 5.274246\tLR: 0.000607\n",
            "Train Epoch: 2 [23000/28539 (81%)]\tLoss: 5.205345\tLR: 0.000618\n",
            "Train Epoch: 2 [24000/28539 (84%)]\tLoss: 5.208617\tLR: 0.000629\n",
            "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 4.894951\tLR: 0.000640\n",
            "Train Epoch: 2 [26000/28539 (91%)]\tLoss: 5.461395\tLR: 0.000652\n",
            "Train Epoch: 2 [27000/28539 (95%)]\tLoss: 5.368482\tLR: 0.000663\n",
            "Train Epoch: 2 [28000/28539 (98%)]\tLoss: 5.120448\tLR: 0.000674\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 4.8862, Average CER: 0.764978 Average WER: 0.8687\n",
            "\n",
            "Sat May  8 00:03:23 UTC 2021\n",
            "Train Epoch: 3 [0/28539 (0%)]\tLoss: 5.070038\tLR: 0.000680\n",
            "Train Epoch: 3 [1000/28539 (4%)]\tLoss: 5.418457\tLR: 0.000691\n",
            "Train Epoch: 3 [2000/28539 (7%)]\tLoss: 4.994422\tLR: 0.000703\n",
            "Train Epoch: 3 [3000/28539 (11%)]\tLoss: 5.447978\tLR: 0.000714\n",
            "Train Epoch: 3 [4000/28539 (14%)]\tLoss: 5.309944\tLR: 0.000725\n",
            "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 4.923997\tLR: 0.000736\n",
            "Train Epoch: 3 [6000/28539 (21%)]\tLoss: 5.142769\tLR: 0.000747\n",
            "Train Epoch: 3 [7000/28539 (25%)]\tLoss: 4.645734\tLR: 0.000759\n",
            "Train Epoch: 3 [8000/28539 (28%)]\tLoss: 4.979085\tLR: 0.000770\n",
            "Train Epoch: 3 [9000/28539 (32%)]\tLoss: 5.055873\tLR: 0.000781\n",
            "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 4.853648\tLR: 0.000792\n",
            "Train Epoch: 3 [11000/28539 (39%)]\tLoss: 5.118386\tLR: 0.000804\n",
            "Train Epoch: 3 [12000/28539 (42%)]\tLoss: 4.789643\tLR: 0.000815\n",
            "Train Epoch: 3 [13000/28539 (46%)]\tLoss: 4.814443\tLR: 0.000826\n",
            "Train Epoch: 3 [14000/28539 (49%)]\tLoss: 4.887559\tLR: 0.000837\n",
            "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 5.153343\tLR: 0.000848\n",
            "Train Epoch: 3 [16000/28539 (56%)]\tLoss: 4.987537\tLR: 0.000860\n",
            "Train Epoch: 3 [17000/28539 (60%)]\tLoss: 4.401402\tLR: 0.000871\n",
            "Train Epoch: 3 [18000/28539 (63%)]\tLoss: 4.799230\tLR: 0.000882\n",
            "Train Epoch: 3 [19000/28539 (67%)]\tLoss: 4.938310\tLR: 0.000893\n",
            "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 4.746801\tLR: 0.000904\n",
            "Train Epoch: 3 [21000/28539 (74%)]\tLoss: 4.623869\tLR: 0.000916\n",
            "Train Epoch: 3 [22000/28539 (77%)]\tLoss: 4.787691\tLR: 0.000927\n",
            "Train Epoch: 3 [23000/28539 (81%)]\tLoss: 4.814672\tLR: 0.000938\n",
            "Train Epoch: 3 [24000/28539 (84%)]\tLoss: 4.775430\tLR: 0.000949\n",
            "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 4.735715\tLR: 0.000961\n",
            "Train Epoch: 3 [26000/28539 (91%)]\tLoss: 4.592324\tLR: 0.000972\n",
            "Train Epoch: 3 [27000/28539 (95%)]\tLoss: 4.935316\tLR: 0.000983\n",
            "Train Epoch: 3 [28000/28539 (98%)]\tLoss: 4.725890\tLR: 0.000994\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 4.2889, Average CER: 0.641995 Average WER: 0.7987\n",
            "\n",
            "Sat May  8 00:13:47 UTC 2021\n",
            "Train Epoch: 4 [0/28539 (0%)]\tLoss: 4.624618\tLR: 0.001000\n",
            "Train Epoch: 4 [1000/28539 (4%)]\tLoss: 4.833268\tLR: 0.000995\n",
            "Train Epoch: 4 [2000/28539 (7%)]\tLoss: 4.644696\tLR: 0.000990\n",
            "Train Epoch: 4 [3000/28539 (11%)]\tLoss: 4.639291\tLR: 0.000985\n",
            "Train Epoch: 4 [4000/28539 (14%)]\tLoss: 4.583451\tLR: 0.000980\n",
            "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 4.585273\tLR: 0.000975\n",
            "Train Epoch: 4 [6000/28539 (21%)]\tLoss: 4.609611\tLR: 0.000970\n",
            "Train Epoch: 4 [7000/28539 (25%)]\tLoss: 4.818323\tLR: 0.000965\n",
            "Train Epoch: 4 [8000/28539 (28%)]\tLoss: 3.972031\tLR: 0.000960\n",
            "Train Epoch: 4 [9000/28539 (32%)]\tLoss: 4.861034\tLR: 0.000955\n",
            "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 4.631765\tLR: 0.000950\n",
            "Train Epoch: 4 [11000/28539 (39%)]\tLoss: 4.674203\tLR: 0.000945\n",
            "Train Epoch: 4 [12000/28539 (42%)]\tLoss: 4.537690\tLR: 0.000940\n",
            "Train Epoch: 4 [13000/28539 (46%)]\tLoss: 4.630840\tLR: 0.000935\n",
            "Train Epoch: 4 [14000/28539 (49%)]\tLoss: 4.972964\tLR: 0.000930\n",
            "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 4.747749\tLR: 0.000925\n",
            "Train Epoch: 4 [16000/28539 (56%)]\tLoss: 4.587430\tLR: 0.000920\n",
            "Train Epoch: 4 [17000/28539 (60%)]\tLoss: 4.327804\tLR: 0.000915\n",
            "Train Epoch: 4 [18000/28539 (63%)]\tLoss: 4.121680\tLR: 0.000910\n",
            "Train Epoch: 4 [19000/28539 (67%)]\tLoss: 4.702386\tLR: 0.000905\n",
            "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 4.435782\tLR: 0.000900\n",
            "Train Epoch: 4 [21000/28539 (74%)]\tLoss: 4.499433\tLR: 0.000895\n",
            "Train Epoch: 4 [22000/28539 (77%)]\tLoss: 4.379106\tLR: 0.000890\n",
            "Train Epoch: 4 [23000/28539 (81%)]\tLoss: 4.183766\tLR: 0.000885\n",
            "Train Epoch: 4 [24000/28539 (84%)]\tLoss: 4.125965\tLR: 0.000880\n",
            "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 4.535967\tLR: 0.000875\n",
            "Train Epoch: 4 [26000/28539 (91%)]\tLoss: 4.441625\tLR: 0.000870\n",
            "Train Epoch: 4 [27000/28539 (95%)]\tLoss: 4.102516\tLR: 0.000865\n",
            "Train Epoch: 4 [28000/28539 (98%)]\tLoss: 4.089907\tLR: 0.000860\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 3.6707, Average CER: 0.549232 Average WER: 0.7262\n",
            "\n",
            "Sat May  8 00:24:55 UTC 2021\n",
            "Train Epoch: 5 [0/28539 (0%)]\tLoss: 3.902666\tLR: 0.000857\n",
            "Train Epoch: 5 [1000/28539 (4%)]\tLoss: 4.189885\tLR: 0.000852\n",
            "Train Epoch: 5 [2000/28539 (7%)]\tLoss: 3.946101\tLR: 0.000847\n",
            "Train Epoch: 5 [3000/28539 (11%)]\tLoss: 3.822058\tLR: 0.000842\n",
            "Train Epoch: 5 [4000/28539 (14%)]\tLoss: 3.754586\tLR: 0.000837\n",
            "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 3.740934\tLR: 0.000832\n",
            "Train Epoch: 5 [6000/28539 (21%)]\tLoss: 3.863225\tLR: 0.000827\n",
            "Train Epoch: 5 [7000/28539 (25%)]\tLoss: 3.773616\tLR: 0.000822\n",
            "Train Epoch: 5 [8000/28539 (28%)]\tLoss: 3.867498\tLR: 0.000817\n",
            "Train Epoch: 5 [9000/28539 (32%)]\tLoss: 3.925074\tLR: 0.000812\n",
            "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 4.073742\tLR: 0.000807\n",
            "Train Epoch: 5 [11000/28539 (39%)]\tLoss: 3.747732\tLR: 0.000802\n",
            "Train Epoch: 5 [12000/28539 (42%)]\tLoss: 3.419233\tLR: 0.000797\n",
            "Train Epoch: 5 [13000/28539 (46%)]\tLoss: 3.842652\tLR: 0.000792\n",
            "Train Epoch: 5 [14000/28539 (49%)]\tLoss: 3.651168\tLR: 0.000787\n",
            "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 3.691930\tLR: 0.000782\n",
            "Train Epoch: 5 [16000/28539 (56%)]\tLoss: 3.390234\tLR: 0.000777\n",
            "Train Epoch: 5 [17000/28539 (60%)]\tLoss: 3.431282\tLR: 0.000772\n",
            "Train Epoch: 5 [18000/28539 (63%)]\tLoss: 3.403530\tLR: 0.000767\n",
            "Train Epoch: 5 [19000/28539 (67%)]\tLoss: 4.076526\tLR: 0.000762\n",
            "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 3.423553\tLR: 0.000757\n",
            "Train Epoch: 5 [21000/28539 (74%)]\tLoss: 4.023041\tLR: 0.000752\n",
            "Train Epoch: 5 [22000/28539 (77%)]\tLoss: 3.589930\tLR: 0.000747\n",
            "Train Epoch: 5 [23000/28539 (81%)]\tLoss: 3.484160\tLR: 0.000742\n",
            "Train Epoch: 5 [24000/28539 (84%)]\tLoss: 3.188579\tLR: 0.000737\n",
            "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 3.551989\tLR: 0.000732\n",
            "Train Epoch: 5 [26000/28539 (91%)]\tLoss: 3.137432\tLR: 0.000727\n",
            "Train Epoch: 5 [27000/28539 (95%)]\tLoss: 3.488846\tLR: 0.000722\n",
            "Train Epoch: 5 [28000/28539 (98%)]\tLoss: 3.187975\tLR: 0.000717\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.9451, Average CER: 0.421262 Average WER: 0.6161\n",
            "\n",
            "Sat May  8 00:36:53 UTC 2021\n",
            "Train Epoch: 6 [0/28539 (0%)]\tLoss: 3.030920\tLR: 0.000714\n",
            "Train Epoch: 6 [1000/28539 (4%)]\tLoss: 3.241415\tLR: 0.000709\n",
            "Train Epoch: 6 [2000/28539 (7%)]\tLoss: 3.314355\tLR: 0.000704\n",
            "Train Epoch: 6 [3000/28539 (11%)]\tLoss: 3.604044\tLR: 0.000699\n",
            "Train Epoch: 6 [4000/28539 (14%)]\tLoss: 3.338143\tLR: 0.000694\n",
            "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 3.365569\tLR: 0.000689\n",
            "Train Epoch: 6 [6000/28539 (21%)]\tLoss: 3.273225\tLR: 0.000684\n",
            "Train Epoch: 6 [7000/28539 (25%)]\tLoss: 3.354326\tLR: 0.000679\n",
            "Train Epoch: 6 [8000/28539 (28%)]\tLoss: 3.174377\tLR: 0.000674\n",
            "Train Epoch: 6 [9000/28539 (32%)]\tLoss: 3.196548\tLR: 0.000669\n",
            "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 3.479354\tLR: 0.000664\n",
            "Train Epoch: 6 [11000/28539 (39%)]\tLoss: 3.260267\tLR: 0.000659\n",
            "Train Epoch: 6 [12000/28539 (42%)]\tLoss: 3.374526\tLR: 0.000654\n",
            "Train Epoch: 6 [13000/28539 (46%)]\tLoss: 3.237626\tLR: 0.000649\n",
            "Train Epoch: 6 [14000/28539 (49%)]\tLoss: 3.680523\tLR: 0.000644\n",
            "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 3.331900\tLR: 0.000639\n",
            "Train Epoch: 6 [16000/28539 (56%)]\tLoss: 3.337759\tLR: 0.000634\n",
            "Train Epoch: 6 [17000/28539 (60%)]\tLoss: 3.898309\tLR: 0.000629\n",
            "Train Epoch: 6 [18000/28539 (63%)]\tLoss: 2.967719\tLR: 0.000624\n",
            "Train Epoch: 6 [19000/28539 (67%)]\tLoss: 3.125717\tLR: 0.000619\n",
            "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 3.566581\tLR: 0.000614\n",
            "Train Epoch: 6 [21000/28539 (74%)]\tLoss: 3.044081\tLR: 0.000609\n",
            "Train Epoch: 6 [22000/28539 (77%)]\tLoss: 2.984319\tLR: 0.000604\n",
            "Train Epoch: 6 [23000/28539 (81%)]\tLoss: 3.560327\tLR: 0.000599\n",
            "Train Epoch: 6 [24000/28539 (84%)]\tLoss: 3.053452\tLR: 0.000594\n",
            "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 2.973967\tLR: 0.000589\n",
            "Train Epoch: 6 [26000/28539 (91%)]\tLoss: 3.114827\tLR: 0.000584\n",
            "Train Epoch: 6 [27000/28539 (95%)]\tLoss: 3.217822\tLR: 0.000579\n",
            "Train Epoch: 6 [28000/28539 (98%)]\tLoss: 3.064291\tLR: 0.000574\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.6035, Average CER: 0.383968 Average WER: 0.5724\n",
            "\n",
            "Sat May  8 00:48:51 UTC 2021\n",
            "Train Epoch: 7 [0/28539 (0%)]\tLoss: 3.175291\tLR: 0.000571\n",
            "Train Epoch: 7 [1000/28539 (4%)]\tLoss: 2.719580\tLR: 0.000566\n",
            "Train Epoch: 7 [2000/28539 (7%)]\tLoss: 3.020335\tLR: 0.000561\n",
            "Train Epoch: 7 [3000/28539 (11%)]\tLoss: 2.983001\tLR: 0.000556\n",
            "Train Epoch: 7 [4000/28539 (14%)]\tLoss: 2.909388\tLR: 0.000551\n",
            "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 2.937099\tLR: 0.000546\n",
            "Train Epoch: 7 [6000/28539 (21%)]\tLoss: 3.073853\tLR: 0.000541\n",
            "Train Epoch: 7 [7000/28539 (25%)]\tLoss: 2.797084\tLR: 0.000536\n",
            "Train Epoch: 7 [8000/28539 (28%)]\tLoss: 3.245282\tLR: 0.000531\n",
            "Train Epoch: 7 [9000/28539 (32%)]\tLoss: 3.070700\tLR: 0.000526\n",
            "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 2.637846\tLR: 0.000521\n",
            "Train Epoch: 7 [11000/28539 (39%)]\tLoss: 2.948393\tLR: 0.000516\n",
            "Train Epoch: 7 [12000/28539 (42%)]\tLoss: 3.151863\tLR: 0.000511\n",
            "Train Epoch: 7 [13000/28539 (46%)]\tLoss: 2.785854\tLR: 0.000506\n",
            "Train Epoch: 7 [14000/28539 (49%)]\tLoss: 2.891026\tLR: 0.000501\n",
            "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 3.192199\tLR: 0.000496\n",
            "Train Epoch: 7 [16000/28539 (56%)]\tLoss: 2.769509\tLR: 0.000491\n",
            "Train Epoch: 7 [17000/28539 (60%)]\tLoss: 2.761812\tLR: 0.000486\n",
            "Train Epoch: 7 [18000/28539 (63%)]\tLoss: 2.703018\tLR: 0.000481\n",
            "Train Epoch: 7 [19000/28539 (67%)]\tLoss: 3.266354\tLR: 0.000476\n",
            "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 3.013171\tLR: 0.000471\n",
            "Train Epoch: 7 [21000/28539 (74%)]\tLoss: 2.693823\tLR: 0.000466\n",
            "Train Epoch: 7 [22000/28539 (77%)]\tLoss: 3.121644\tLR: 0.000461\n",
            "Train Epoch: 7 [23000/28539 (81%)]\tLoss: 2.554303\tLR: 0.000456\n",
            "Train Epoch: 7 [24000/28539 (84%)]\tLoss: 3.086833\tLR: 0.000451\n",
            "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 2.674268\tLR: 0.000446\n",
            "Train Epoch: 7 [26000/28539 (91%)]\tLoss: 3.130710\tLR: 0.000441\n",
            "Train Epoch: 7 [27000/28539 (95%)]\tLoss: 2.926009\tLR: 0.000436\n",
            "Train Epoch: 7 [28000/28539 (98%)]\tLoss: 2.786557\tLR: 0.000431\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.3664, Average CER: 0.337513 Average WER: 0.5319\n",
            "\n",
            "Sat May  8 01:00:56 UTC 2021\n",
            "Train Epoch: 8 [0/28539 (0%)]\tLoss: 2.777666\tLR: 0.000428\n",
            "Train Epoch: 8 [1000/28539 (4%)]\tLoss: 2.663428\tLR: 0.000423\n",
            "Train Epoch: 8 [2000/28539 (7%)]\tLoss: 3.128880\tLR: 0.000418\n",
            "Train Epoch: 8 [3000/28539 (11%)]\tLoss: 2.763853\tLR: 0.000413\n",
            "Train Epoch: 8 [4000/28539 (14%)]\tLoss: 2.560644\tLR: 0.000408\n",
            "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 2.742617\tLR: 0.000403\n",
            "Train Epoch: 8 [6000/28539 (21%)]\tLoss: 2.584247\tLR: 0.000398\n",
            "Train Epoch: 8 [7000/28539 (25%)]\tLoss: 2.876015\tLR: 0.000393\n",
            "Train Epoch: 8 [8000/28539 (28%)]\tLoss: 2.753725\tLR: 0.000388\n",
            "Train Epoch: 8 [9000/28539 (32%)]\tLoss: 2.516611\tLR: 0.000383\n",
            "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 2.691837\tLR: 0.000378\n",
            "Train Epoch: 8 [11000/28539 (39%)]\tLoss: 2.900200\tLR: 0.000373\n",
            "Train Epoch: 8 [12000/28539 (42%)]\tLoss: 2.168820\tLR: 0.000368\n",
            "Train Epoch: 8 [13000/28539 (46%)]\tLoss: 2.960646\tLR: 0.000363\n",
            "Train Epoch: 8 [14000/28539 (49%)]\tLoss: 2.759516\tLR: 0.000358\n",
            "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 2.730174\tLR: 0.000353\n",
            "Train Epoch: 8 [16000/28539 (56%)]\tLoss: 2.822701\tLR: 0.000348\n",
            "Train Epoch: 8 [17000/28539 (60%)]\tLoss: 2.734856\tLR: 0.000343\n",
            "Train Epoch: 8 [18000/28539 (63%)]\tLoss: 2.761109\tLR: 0.000338\n",
            "Train Epoch: 8 [19000/28539 (67%)]\tLoss: 2.576290\tLR: 0.000333\n",
            "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 2.713374\tLR: 0.000328\n",
            "Train Epoch: 8 [21000/28539 (74%)]\tLoss: 2.412234\tLR: 0.000323\n",
            "Train Epoch: 8 [22000/28539 (77%)]\tLoss: 2.566166\tLR: 0.000318\n",
            "Train Epoch: 8 [23000/28539 (81%)]\tLoss: 2.525761\tLR: 0.000313\n",
            "Train Epoch: 8 [24000/28539 (84%)]\tLoss: 2.632055\tLR: 0.000308\n",
            "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 2.755566\tLR: 0.000303\n",
            "Train Epoch: 8 [26000/28539 (91%)]\tLoss: 2.629764\tLR: 0.000298\n",
            "Train Epoch: 8 [27000/28539 (95%)]\tLoss: 2.609128\tLR: 0.000293\n",
            "Train Epoch: 8 [28000/28539 (98%)]\tLoss: 2.889865\tLR: 0.000288\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.2077, Average CER: 0.308097 Average WER: 0.5090\n",
            "\n",
            "Sat May  8 01:13:18 UTC 2021\n",
            "Train Epoch: 9 [0/28539 (0%)]\tLoss: 2.530916\tLR: 0.000286\n",
            "Train Epoch: 9 [1000/28539 (4%)]\tLoss: 2.698689\tLR: 0.000281\n",
            "Train Epoch: 9 [2000/28539 (7%)]\tLoss: 2.566475\tLR: 0.000276\n",
            "Train Epoch: 9 [3000/28539 (11%)]\tLoss: 2.498351\tLR: 0.000271\n",
            "Train Epoch: 9 [4000/28539 (14%)]\tLoss: 2.384259\tLR: 0.000266\n",
            "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 2.744260\tLR: 0.000261\n",
            "Train Epoch: 9 [6000/28539 (21%)]\tLoss: 2.416678\tLR: 0.000256\n",
            "Train Epoch: 9 [7000/28539 (25%)]\tLoss: 2.699442\tLR: 0.000251\n",
            "Train Epoch: 9 [8000/28539 (28%)]\tLoss: 2.478687\tLR: 0.000246\n",
            "Train Epoch: 9 [9000/28539 (32%)]\tLoss: 2.230560\tLR: 0.000241\n",
            "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 2.353805\tLR: 0.000236\n",
            "Train Epoch: 9 [11000/28539 (39%)]\tLoss: 2.276982\tLR: 0.000231\n",
            "Train Epoch: 9 [12000/28539 (42%)]\tLoss: 2.663586\tLR: 0.000226\n",
            "Train Epoch: 9 [13000/28539 (46%)]\tLoss: 2.729818\tLR: 0.000221\n",
            "Train Epoch: 9 [14000/28539 (49%)]\tLoss: 2.345521\tLR: 0.000216\n",
            "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 2.279125\tLR: 0.000211\n",
            "Train Epoch: 9 [16000/28539 (56%)]\tLoss: 2.693343\tLR: 0.000206\n",
            "Train Epoch: 9 [17000/28539 (60%)]\tLoss: 2.981220\tLR: 0.000201\n",
            "Train Epoch: 9 [18000/28539 (63%)]\tLoss: 2.608375\tLR: 0.000196\n",
            "Train Epoch: 9 [19000/28539 (67%)]\tLoss: 2.796263\tLR: 0.000191\n",
            "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 2.399392\tLR: 0.000186\n",
            "Train Epoch: 9 [21000/28539 (74%)]\tLoss: 2.577857\tLR: 0.000181\n",
            "Train Epoch: 9 [22000/28539 (77%)]\tLoss: 2.565780\tLR: 0.000175\n",
            "Train Epoch: 9 [23000/28539 (81%)]\tLoss: 2.224485\tLR: 0.000170\n",
            "Train Epoch: 9 [24000/28539 (84%)]\tLoss: 2.858747\tLR: 0.000165\n",
            "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 2.607889\tLR: 0.000160\n",
            "Train Epoch: 9 [26000/28539 (91%)]\tLoss: 2.643822\tLR: 0.000155\n",
            "Train Epoch: 9 [27000/28539 (95%)]\tLoss: 2.813597\tLR: 0.000150\n",
            "Train Epoch: 9 [28000/28539 (98%)]\tLoss: 2.377969\tLR: 0.000145\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.0867, Average CER: 0.298874 Average WER: 0.4881\n",
            "\n",
            "Sat May  8 01:25:39 UTC 2021\n",
            "Train Epoch: 10 [0/28539 (0%)]\tLoss: 2.298668\tLR: 0.000143\n",
            "Train Epoch: 10 [1000/28539 (4%)]\tLoss: 2.488280\tLR: 0.000138\n",
            "Train Epoch: 10 [2000/28539 (7%)]\tLoss: 2.402967\tLR: 0.000133\n",
            "Train Epoch: 10 [3000/28539 (11%)]\tLoss: 2.376529\tLR: 0.000128\n",
            "Train Epoch: 10 [4000/28539 (14%)]\tLoss: 2.055771\tLR: 0.000123\n",
            "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 2.326540\tLR: 0.000118\n",
            "Train Epoch: 10 [6000/28539 (21%)]\tLoss: 2.418869\tLR: 0.000113\n",
            "Train Epoch: 10 [7000/28539 (25%)]\tLoss: 2.254887\tLR: 0.000108\n",
            "Train Epoch: 10 [8000/28539 (28%)]\tLoss: 2.144580\tLR: 0.000103\n",
            "Train Epoch: 10 [9000/28539 (32%)]\tLoss: 2.370577\tLR: 0.000098\n",
            "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 2.595356\tLR: 0.000093\n",
            "Train Epoch: 10 [11000/28539 (39%)]\tLoss: 2.327622\tLR: 0.000088\n",
            "Train Epoch: 10 [12000/28539 (42%)]\tLoss: 2.197954\tLR: 0.000083\n",
            "Train Epoch: 10 [13000/28539 (46%)]\tLoss: 2.352547\tLR: 0.000078\n",
            "Train Epoch: 10 [14000/28539 (49%)]\tLoss: 2.430652\tLR: 0.000073\n",
            "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 2.405365\tLR: 0.000068\n",
            "Train Epoch: 10 [16000/28539 (56%)]\tLoss: 2.519240\tLR: 0.000063\n",
            "Train Epoch: 10 [17000/28539 (60%)]\tLoss: 2.426099\tLR: 0.000058\n",
            "Train Epoch: 10 [18000/28539 (63%)]\tLoss: 2.281765\tLR: 0.000053\n",
            "Train Epoch: 10 [19000/28539 (67%)]\tLoss: 2.576741\tLR: 0.000048\n",
            "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 2.314543\tLR: 0.000043\n",
            "Train Epoch: 10 [21000/28539 (74%)]\tLoss: 2.183733\tLR: 0.000038\n",
            "Train Epoch: 10 [22000/28539 (77%)]\tLoss: 2.422426\tLR: 0.000033\n",
            "Train Epoch: 10 [23000/28539 (81%)]\tLoss: 2.478443\tLR: 0.000028\n",
            "Train Epoch: 10 [24000/28539 (84%)]\tLoss: 2.462454\tLR: 0.000023\n",
            "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 2.602679\tLR: 0.000018\n",
            "Train Epoch: 10 [26000/28539 (91%)]\tLoss: 2.373208\tLR: 0.000013\n",
            "Train Epoch: 10 [27000/28539 (95%)]\tLoss: 1.816917\tLR: 0.000008\n",
            "Train Epoch: 10 [28000/28539 (98%)]\tLoss: 2.030587\tLR: 0.000003\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.0235, Average CER: 0.287857 Average WER: 0.4776\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mby39YVqZadd"
      },
      "source": [
        "### <b>Задание №1</b> (5 баллов):\n",
        "На данный момент практически все E2E SOTA решения использую [сабворды](https://dyakonov.org/2019/11/29/%D1%82%D0%BE%D0%BA%D0%B5%D0%BD%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-%D0%BD%D0%B0-%D0%BF%D0%BE%D0%B4%D1%81%D0%BB%D0%BE%D0%B2%D0%B0-subword-tokenization/) (subwords/wordpieces) в качестве таргетов нейронки для распознавания. Нам бы тоже не мешало перейти от графем к сабвордам. Теперь вместо букв (графем) будем распознавать кусочки слов. В качестве такого токенайзера предлагается использовать [Sentencepiece](https://github.com/google/sentencepiece). Главное правильно обернуть его в наш класс TextTransform. Текстовый файл (train_clean_100_text_clean.txt) для обучения токенайзера уже подготовлен и лежит в корневой папке проекта. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOtjm4WNbutB",
        "outputId": "bf85d459-d730-4337-e659-cfd0edc1bc6c"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 23.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 25.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 20.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 14.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 13.8MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 11.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 12.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 12.4MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 12.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 12.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 12.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 12.4MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 12.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 12.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 12.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McBm5u8q__hy"
      },
      "source": [
        "import sentencepiece as spm"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNbiW919e2le"
      },
      "source": [
        "class TextTransformBPE:\n",
        "    def __init__(self, train_text):\n",
        "        \"\"\" Обучение BPE модели на 4000 юнитов\"\"\"\n",
        "        spm.SentencePieceTrainer.train(input=train_text,\n",
        "                                       model_prefix='m', \n",
        "                                       vocab_size=4000,\n",
        "                                       model_type = 'bpe')\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.load('m.model')\n",
        "        # pass\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Преобразование входного текста в последовательность сабвордов в формате их индекса в BPE модели \"\"\"\n",
        "        # int_sequence = []\n",
        "        # pass\n",
        "        int_sequence = self.sp.encode_as_ids(text.upper())#.upper()\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Преобразование последовательности индексов сабвордов в текст \"\"\"\n",
        "        # string = []\n",
        "        # pass\n",
        "        string = self.sp.decode_ids([int(label) for label in labels])\n",
        "        return string"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaCRvuL9SmzY"
      },
      "source": [
        "transform_test = TextTransformBPE('/content/lab4/train_clean_100_text_clean.txt')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDaJXZbNS7oQ",
        "outputId": "c568a63e-9b68-4fa1-a2a9-19eff9607dc0"
      },
      "source": [
        "test_string = 'TEST_Sentence zero NY'\n",
        "transform_test.text_to_int(test_string.lower())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3654, 0, 3981, 66, 300, 3973, 0, 15, 3977, 43, 3991]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8RpRjR-fldKI",
        "outputId": "a023413a-9d43-4df4-ffea-11e7cf908d73"
      },
      "source": [
        "transform_test.int_to_text([3654, 0, 3981, 66, 300, 3973, 0, 15, 3977, 43, 3991])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TEST ⁇ SENTENCE  ⁇ ERO NY'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7jxao4UHyIh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Для baseline модели с TextTransform() обучение на 10 эпохах дало WER порядка 0.5 <br>\n",
        "Для модели с TextTransformBPE аналогичный результат был достигнут к 9 эпохе. Можно сказать, по WER результат модели с сабвордовым токенайзером примерно на эпоху обгонял простой TextTransform().\n",
        "\n",
        "Логи обучения в resources:\n",
        "\n",
        "\n",
        "*   baseline_train_log.txt\n",
        "*   bpe_train_log.txt (my model)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV48Q7HqZsAD"
      },
      "source": [
        "### <b>Задание №2</b> (5 баллов):\n",
        "Импровизация по улучшению качества распознавания."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUeNm_q5kBSP"
      },
      "source": [
        "from espnet.nets.pytorch_backend.conformer.encoder_layer import EncoderLayer"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP3H-W_YcYVz"
      },
      "source": [
        "class ConformerModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size=80,\n",
        "        output_size=29,\n",
        "        conv2d_filters=32,\n",
        "        attention_dim=360,\n",
        "        attention_heads=8,     \n",
        "        feedforward_dim=1024,\n",
        "        num_blocks=10,          \n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super(ConformerModel, self).__init__()\n",
        "        \n",
        "        self.conv_in = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(conv2d_filters, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "        self.conv_out = torch.nn.Sequential(\n",
        "            torch.nn.Linear(conv2d_filters * ((input_size // 2) // 2), attention_dim),\n",
        "            PositionalEncoding(attention_dim, 0.1),\n",
        "        )\n",
        "        positionwise_layer = PositionwiseFeedForward\n",
        "        positionwise_layer_args = (attention_dim, feedforward_dim, dropout)\n",
        "        # self.encoder_layer = repeat(\n",
        "        #     num_layers,\n",
        "        #     lambda lnum: EncoderLayer(\n",
        "        #         attention_dim,\n",
        "        #         MultiHeadedAttention(\n",
        "        #             attention_heads, attention_dim, dropout\n",
        "        #         ),\n",
        "        #         positionwise_layer(*positionwise_layer_args),\n",
        "        #         dropout,\n",
        "        #         normalize_before=True,\n",
        "        #         concat_after=False,\n",
        "        #     ),\n",
        "        # )\n",
        "        macaron_style = False\n",
        "        use_cnn_module = False\n",
        "        self.encoder_layer = repeat(\n",
        "            num_blocks,\n",
        "            lambda lnum: EncoderLayer(\n",
        "                attention_dim,\n",
        "                MultiHeadedAttention(\n",
        "                    attention_heads, attention_dim, dropout\n",
        "                ),\n",
        "                positionwise_layer(*positionwise_layer_args),\n",
        "                positionwise_layer(*positionwise_layer_args) if macaron_style else None,\n",
        "                convolution_layer(*convolution_layer_args) if use_cnn_module else None,\n",
        "                dropout,\n",
        "                normalize_before=True,\n",
        "                concat_after=False,\n",
        "            ),\n",
        "        )\n",
        "        self.after_norm = LayerNorm(attention_dim)\n",
        "        self.final_layer = torch.nn.Linear(attention_dim, output_size)\n",
        "\n",
        "    def forward(self, x, ilens):\n",
        "        x = x.unsqueeze(1)  # (b, c, t, f)\n",
        "        x = self.conv_in(x)\n",
        "        b, c, t, f = x.size()\n",
        "        x = self.conv_out(x.transpose(1, 2).contiguous().view(b, t, c * f))\n",
        "        masks = (~make_pad_mask(ilens)[:, None, :])[:, :, ::4].to(x.device)\n",
        "        x, _, _ = self.encoder_layer(x, masks)\n",
        "        x = self.after_norm(x)\n",
        "        x = self.final_layer(x)\n",
        "        return x"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmdcGERsF1GG"
      },
      "source": [
        "Модель ConformerModel с TextTransformBPE и теми же входными параметрами обучения, что и у двух предыдущих, для 10 эпох показала результат 0.48\n",
        "\n",
        "Логи обучения в resources:\n",
        "\n",
        "*   conformer_bpe_train_log.txt (my model)\n",
        "\n",
        "График обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "0eGyUyfQA2xJ",
        "outputId": "618a5896-7418-4a49-cf4e-200b7c7a4e4f"
      },
      "source": [
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "ax.plot(train_history, label='train history', marker = 'o')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.plot(val_history, label='valid history', marker = 'o')\n",
        "\n",
        "plt.legend()\n",
        "plt.grid()           \n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YiMSyTVGPFD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}