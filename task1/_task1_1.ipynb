{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "\"Самостоятельная_1.ipynb\"",
      "provenance": [],
      "collapsed_sections": [
        "EZ3norIudP05",
        "37kWjL7yjJr7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71jkH8V2P_vu"
      },
      "source": [
        "# Самостоятельная работа № 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSERdE-o3YNJ"
      },
      "source": [
        "### Задание 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qK0YE-MQDo7"
      },
      "source": [
        "Модуль лингвистической предобработки текста является одним из важнейших компонентов современных TTS систем.\n",
        "Стандартный набор преобразований над текстом включает в себя:\n",
        "- нормализацию \n",
        "- токенизацию \n",
        "- построение транскрипции\n",
        "\n",
        "Нормализация подразумевает расшифровку числовых последовательностей, дат, оббревиатур, иноязычных вставок, сокращений и т.д. (не путать с приведением к нормальной форме слов - принятой терминологиией в NLP).\n",
        "\n",
        "Токенизация - разбиение текста на предложения и слова.\n",
        "\n",
        "Построение транскрипции позволяет получить из графемного фонемное представление текста. На этом же этапе разрешается пробелма расстановки ударений. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGqr7N5dQDzd"
      },
      "source": [
        "Предлагается построить простой пайплайн лингвистической предобработки: токенизация на предложения, нормализация каждого предложения, получение фонемной последовательности для каждого предложения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxzPFZYKAsTK"
      },
      "source": [
        "### Инструкция по установке и подключению сторонних библиотек из репозиторией (если не устанавливается через pip)\n",
        "1. Склонировать репозиторий \n",
        "\n",
        "*!git clone путь к репозиторию*\n",
        "\n",
        "2. Добавить корень репо в PATH\n",
        "\n",
        "*sys.path.append(\"корень склонированного репо\")*\n",
        "\n",
        "3. Установить необходимые зависимости для репо\n",
        "\n",
        "*!pip install название библиотеки*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H8OEwg0COcW"
      },
      "source": [
        "# утрановка необходимых библиотек\n",
        "\n",
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l75cEfyEBAI7"
      },
      "source": [
        "# Импорт необходимых библиотек\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import uuid\n",
        "import torch\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lSQ4YRP9Qlv"
      },
      "source": [
        "# ваш номер\n",
        "my_id = uuid.uuid4().hex\n",
        "print(my_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OORivVaHCSQk"
      },
      "source": [
        "# Исходный текст\n",
        "input_text = \"В 1785 г в городе Augsburg случилось странное проишествие. Группа в 18 человек, где каждый весил не менее 100 кг, устроила праздник на втором этаже деревянного здания.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5x5nLUxFIWv"
      },
      "source": [
        "# Используйте razdel отсюда https://github.com/natasha/razdel\n",
        "\n",
        "def tokenize_by_sent(text):\n",
        "   \"Возвращает список токенизированных предложений\"\n",
        "   pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIx3RvwMDlvO"
      },
      "source": [
        "sentences = tokenize_by_sent(input_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05TiyhSNElpl"
      },
      "source": [
        "print(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFSgVlRIfoLH"
      },
      "source": [
        "Токенизация на предложения нужна и при подготовке обучающих баз и при инференсе системы. Обучать модель на длинных текстах как правило не целесообразно. \n",
        "\n",
        "Токенизация на слова может понадобится для получения границ слов, получения знаков препринания, может требоваться для более качественной нормализации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4rCUFwq5sND"
      },
      "source": [
        "# Для реализации функции воспользуйтесь инструментом Normalizer из этого репозитория https://github.com/snakers4/russian_stt_text_normalization\n",
        "# подсказка по путям sys.path.append(\"russian_stt_text_normalization\")\n",
        "\n",
        "def normalize(text):\n",
        "  \"Возвращает нормализованное предложение\"\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKo4JNGK5h0Q"
      },
      "source": [
        "norm_sentences = [normalize(sentence) for sentence in sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlH1ikJ85h-r"
      },
      "source": [
        "print(norm_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMS9eqJme83_"
      },
      "source": [
        "Нормализация текста - сложная задача. Далеко не всегда открытые решения хорошо с ней справляются. Нормализация на основе лингвистических баз и правил может справляться с задачей лучше, чем нейросетевая модель."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf5OfWK15iCh"
      },
      "source": [
        "# Для реализации используйте Accentor отсюда https://github.com/nsu-ai/russian_g2p\n",
        "# Для решения проблем с импортом в этой библиотеке лучше перенести папку russian_g2p ближе к корню\n",
        "# os.rename(\"russian_g2p\", \"root_russian_g2p\")\n",
        "# os.replace(\"root_russian_g2p/russian_g2p\", \"russian_g2p\")\n",
        "\n",
        "\n",
        "def g2p(text):\n",
        "  \"Возвращает список из фонем входящего текста\"\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx588JvcLdvY"
      },
      "source": [
        "phonemes_sequences = [g2p(sentence) for sentence in norm_sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ew0L2lqLf09"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we1v-oZ8QvLs"
      },
      "source": [
        "print(phonemes_sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10xdZYfadSBf"
      },
      "source": [
        "# Сохраняем результат себе\n",
        "\n",
        "with open(f\"result_1_{my_id}.txt\", 'w') as f_out:\n",
        "  for sequence in phonemes_sentences:\n",
        "    f_out.write(f'{\" \".join(sequence)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGgmLarNd_Fb"
      },
      "source": [
        "files.download(f\"result_1_{my_id}.txt\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUwic2REbxWc"
      },
      "source": [
        "Насколько можно видеть, итоговая последовательность может представлять из себя простой список из фонем, к котором не видно границ слов или знаков препинания.\n",
        "В самом просто варианте, границы слов можно обозначить пробельным символом. Однако знаки препинания лучше исключить из финальной последовательности, т.к. их наличие будет мешать модели выстраивать матрицу внимания (какой длительности будет многоточие или знак вопроса?). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ3norIudP05"
      },
      "source": [
        "### Задание 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvlBYiiidP6I"
      },
      "source": [
        "Пайплайн получения признаков из аудио для TTS может быть достаточно сложным.\n",
        "Последовательность обработчиков и их параметры будут зависеть в том числе и от особенностей вокодера. \n",
        "Наиболее распространенным вариантом акустических признаков является логарифмированная мел-спектрограмма.\n",
        "\n",
        "Задание - реализовать функции построения мел-спектрограммы с заданными параметрами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIbYjDDxiG2p"
      },
      "source": [
        "Общий вид пайплайна такой: Входной сигнал -> Pre-emphasis -> STFT -> Магнитуда-> Мел-скейл -> Логарифмирование"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_tKQUIZm484"
      },
      "source": [
        "# примонтировать свой диск (куда заранее положили нужный wav файл)\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ94ElLph9Fy"
      },
      "source": [
        "# загрузки входного сигнала (скорее всего путь будет таким 'gdrive/MyDrive/audio_sample/example.wav') \n",
        "# можно воспользоваться librosa\n",
        "\n",
        "def read_wave(wave_path):\n",
        "  \"возвращает волну и sample rate\"\n",
        "  pass\n",
        "\n",
        "wave_path = \"\"\n",
        "wave, sr = read_wave(wave_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_mZZbmoqqi"
      },
      "source": [
        "print(f\"Sample rate = {sr}\")\n",
        "print(f\"Wave max = {np.max(wave)} Wave min {np.min(wave)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmXUc-6NyZwQ"
      },
      "source": [
        "plt.figure(figsize=(30, 5))\n",
        "plt.plot(wave)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48txylSUojKU"
      },
      "source": [
        "Данные могут быть в формате float32 или int16 (обычно ...). Нужно привести к формату float32 в диапазоне значений [0, 1]. Стоит обратить внимание на максимальное и минимальное значение (если значения близки к максимум и минимуму диапазона, возможно они были нормализованы или даже клипированы). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW2QHyszh9Jx"
      },
      "source": [
        "# Pre-emphasis\n",
        "# y_t = x_t − α * x_t − 1\n",
        "# α = 0.97\n",
        "\n",
        "def preemphasis(x, coef=0.85):\n",
        "    pass\n",
        "\n",
        "preemh_wave = preemphasis(wave, 0.97)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1DeygPMyiRW"
      },
      "source": [
        "plt.figure(figsize=(30, 5))\n",
        "plt.plot(preemh_wave )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBeHUDJ4jo9x"
      },
      "source": [
        "Обратимое преобразование. Усиливает высокие частоты, ослабляет низкие. \n",
        "\n",
        "В вокодерах необходим для уменьшения высокочастотного шума при мю-кодировании.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwOxEL4gioFu"
      },
      "source": [
        "# STFT (можно воспользоваться librosa)\n",
        "# window = 1024, hop = 256, паддинг reflect, центрировать не надо, окно Ханна\n",
        "\n",
        "\n",
        "def get_stft(data, n_fft, hop, window):\n",
        "  pass\n",
        "\n",
        "stft_features = get_stft(preemh_wave, 1024, 256, 'hann')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MOwhlnBjpll"
      },
      "source": [
        "Short-time Fourier transform. Комплексные значения признаков. \n",
        "\n",
        "Окно анализа обычно соразмерно средней длине фонемы, шаг близким к средней длине коротких фонем (эвристические соображения от которых стоит отталкиваться)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lyhmznsioIo"
      },
      "source": [
        "# Магнитуда\n",
        "# получить амплитудный спектр\n",
        "\n",
        "def get_magnitude(features):\n",
        "  pass\n",
        "\n",
        "magnitude_features = get_magnitude(stft_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST8Uggbc323I"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(magnitude_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLKXiRFYjqGX"
      },
      "source": [
        "Теряется информация о фазе (фазовые признаки значительно менее структурированы). Признаки все еще довольно большого размера. В некоторых моделях TTS применяются и такие."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_hzSV3rioLb"
      },
      "source": [
        "# Мел-скейл. Реализуется в матричном виде как X_mel = Mel_basis * X, где Mel_basis \n",
        "# 100 бинов без ограничений частот (можно воспользоваться librosa.filters)\n",
        "\n",
        "def get_mel_features(magnitude_features, mel_basis):\n",
        "  pass\n",
        "\n",
        "def get_mel_basis(sample_rate, size):\n",
        "  pass\n",
        "\n",
        "mel_basis = lget_mel_basis(sr, 100)\n",
        "mel_features = get_mel_features(magnitude_features, mel_basis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkdOjJdH7vKK"
      },
      "source": [
        "print(f\"max {mel_features.max()} min {mel_features.min()} mean {mel_features.mean()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w8NXM897Rhk"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(mel_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ByKM3QTjqk1"
      },
      "source": [
        "Значительно уменьшается размер признаков, при этом практически не теряется воспринимаемое акустическое качество."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WIqoJiKioOR"
      },
      "source": [
        "# Логарифмирование\n",
        "# амплитуды лучше логарифмировать ln(x), 1e-5 установить минимальным значением под логарифмом (для вычислительной стабильности)\n",
        "# 20log10(x) был бы перевод в децибелы, но разница в константе, поэтому можно не усложнять\n",
        "\n",
        "def get_log_features(features):\n",
        "  pass\n",
        "\n",
        "log_mel_features = get_log_features(mel_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFeKapjK8QWA"
      },
      "source": [
        "print(f\"max {log_mel_features.max()} min {log_mel_features.min()} mean {log_mel_features.mean()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeNiEsqj8VCO"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(log_mel_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmMeYL3hjrHN"
      },
      "source": [
        "Такие признаки уже можно нормализовать.\n",
        "\n",
        "Совет - посмотрите, как будет выглядеть эти же признаки без pre-emphasis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpCrxK2R80gt"
      },
      "source": [
        "# Выгрузим результат\n",
        "np.save(f\"log_mel_features_{my_id}.npy\", log_mel_features)\n",
        "files.download(f\"log_mel_features_{my_id}.npy\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37kWjL7yjJr7"
      },
      "source": [
        "### Задание 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVfqRdLDjJvV"
      },
      "source": [
        "Механизм внимания позволяет модели отображать последовательность фонем на спектрограмму. Базовый вариант, предложенный в модели Tacotron 1, называется content based attention.\n",
        "\n",
        "Этот простой механизм пришел в TTS из области машинного перевода и он не учитывает многих особенностей синтеза речи. В главном это монотонный и локальный характер внимания. \n",
        "\n",
        "Монотонность обеспечивается тем, что порядок звуков и фонем одинаковый (если одна фонема находится в порядке после другой, то и ее признаки в спектрограмме будут находится после признаков первой, в отличие от задачи машинного перевода, где порядок слов в разных языках может отличаться). \n",
        "\n",
        "Локальность обеспечивается тем, что фонемы влияют на звучание только своих ближайших соседей.\n",
        "\n",
        "Не очень подходящий механзм внимания значительно влияет на качество и естественность речи. Непрерывные длинные участки речи с ним вообще крайне затруднительно синтезировать (внимание \"ломается\", \"рассыпается\", пропадают звуки, слова, речь заедает, звучит \"белиберда\", ломается голос, интонации).\n",
        "\n",
        "Разработано уже много вариантов улучшения механизма внимания. А одни из лучших способов - сразу прогнозировать длительность фонем.\n",
        "\n",
        "Попробуем на игрушечном примере построить один из рабочих вариантов механизма внимания FORWARD ATTENTION (https://arxiv.org/pdf/1807.06736.pdf). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMUswxj7yYQf"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st9e_ggWyW7d"
      },
      "source": [
        "seq_len = 100\n",
        "enc_size = 32\n",
        "attn_rnn_size = 16\n",
        "dec_rnn_size = 16\n",
        "attn_inner_size = 32\n",
        "decoder_steps = 200 # у нас нет остановки, поэтому зададим заранее количество шагов декодера"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q15ER3FkxKey"
      },
      "source": [
        "# загрузим заранее сгенерированный вектор\n",
        "encoder_output = torch.from_numpy(np.load(\"gdrive/MyDrive/encoder_output.npy\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bn5q4k7O7Za"
      },
      "source": [
        "class Attention(torch.nn.Module):\n",
        "  def __init__(self, query_size, key_size, attn_inner_size):\n",
        "    super(Attention, self).__init__()\n",
        "    self.softmax = torch.nn.Softmax(dim=0)\n",
        "    self.query = torch.nn.Linear(query_size, attn_inner_size, bias=False)\n",
        "    self.key = torch.nn.Linear(key_size, attn_inner_size, bias=False)\n",
        "    self.v = torch.nn.Linear(attn_inner_size, 1, bias=False)\n",
        "\n",
        "  def forward(self, queries, keys):\n",
        "    keys = self.key(keys)\n",
        "    queries = self.query(queries)\n",
        "    attn = self.v(torch.tanh((queries + keys)).squeeze())\n",
        "    attn = self.softmax(attn)\n",
        "    return attn\n",
        "\n",
        "\n",
        "class SimpleAttnDecoder(torch.nn.Module):\n",
        "  def __init__(self, enc_size, attn_rnn_size, dec_rnn_size, attn_inner_size):\n",
        "    super(SimpleAttnDecoder, self).__init__()\n",
        "    self.attn_rnn_size = attn_rnn_size\n",
        "    self.dec_rnn_size = dec_rnn_size\n",
        "    self.enc_size = enc_size\n",
        "    self.attention = Attention(attn_rnn_size, enc_size, attn_inner_size)\n",
        "    self.rnn_attn = torch.nn.RNNCell(input_size=enc_size, hidden_size=attn_rnn_size)\n",
        "    self.rnn_decoder = torch.nn.RNNCell(input_size=enc_size, hidden_size=dec_rnn_size)\n",
        "\n",
        "  def forward(self, encoder_output, output_len):\n",
        "    attention_matrix = []\n",
        "    outputs = []\n",
        "    attention_state = torch.zeros(1, self.attn_rnn_size).float()\n",
        "    decoder_state = torch.zeros(1, self.dec_rnn_size).float()\n",
        "    context = torch.zeros(1, self.enc_size).float()\n",
        "    \n",
        "    for idx in range(output_len):\n",
        "      attention_state = self.rnn_attn(context, attention_state)\n",
        "      attention_probs = self.attention(attention_state , encoder_output)\n",
        "      # forward attention - это всего-лишь модификация attention_probs \n",
        "      # допишите класс SimpleAttnDecoder, чтобы в этом месте срабатывал forward attention \n",
        "      # Algorithm 1 из предложенной статьи без transition agent\n",
        "      # . . . тут вставка forward attention\n",
        "      context = torch.mm(encoder_output.squeeze().transpose(0,1), attention_probs).transpose(0,1)\n",
        "      decoder_state = self.rnn_decoder(context, decoder_state)\n",
        "      \n",
        "      attention_matrix.append(attention_probs)\n",
        "      outputs.append(decoder_state)\n",
        "    \n",
        "    attention_matrix = torch.stack(attention_matrix).transpose(0,1).squeeze()\n",
        "    outputs = torch.stack(outputs).transpose(0,1).squeeze()\n",
        "    return outputs, attention_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecyj4FCoyAu0"
      },
      "source": [
        "decoder = SimpleAttnDecoder(enc_size, attn_rnn_size, dec_rnn_size, attn_inner_size)\n",
        "decoder.load_state_dict(torch.load(\"gdrive/MyDrive/decoder_state_dict.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnB-uLMeRxaK"
      },
      "source": [
        "with torch.no_grad():\n",
        "  outputs, attention_matrix = decoder(encoder_output, decoder_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAQC6MjVSS3Y"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(attention_matrix.flip(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuHxZWPVb2V-"
      },
      "source": [
        "# Выгрузим готовый результат (матрицу внимания с реализованным forward attention)\n",
        "np.save(f\"attention_{my_id}.npy\", attention_matrix.flip(0).numpy())\n",
        "files.download(f\"attention_{my_id}.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez84ttN7t24V"
      },
      "source": [
        "Матрица внимания будет значительно диагональнее (и это модель со случайным входом и случайными весами!)"
      ]
    }
  ]
}